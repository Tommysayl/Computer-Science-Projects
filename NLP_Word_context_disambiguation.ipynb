{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6d2f954caaf48d8a442c93d42598e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fff377ea8e43457783cb8c0cd063cbe9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90f2647711c54948a8397d7ba8937594",
              "IPY_MODEL_51e3a68893274dddaa9b7ea643aa0850"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "fff377ea8e43457783cb8c0cd063cbe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "90f2647711c54948a8397d7ba8937594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba3b6da00fb64217a4f54bd752ac1e1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3b28ef7adc54b41b8c52e259a5f0ba1"
          },
          "model_module_version": "1.5.0"
        },
        "51e3a68893274dddaa9b7ea643aa0850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_94024185524844579e319e46f3683b4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/? [00:01&lt;00:00, 128.69it/s, epoch=0, loss=0.692]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63d63e19d5414d9f8b99818c3fc27543"
          },
          "model_module_version": "1.5.0"
        },
        "ba3b6da00fb64217a4f54bd752ac1e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "f3b28ef7adc54b41b8c52e259a5f0ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "94024185524844579e319e46f3683b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "63d63e19d5414d9f8b99818c3fc27543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "0d9d3c9c25104702a65403012c61619c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e174503416d54a28ac4f8a93daaf191b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03dea510ae514d0eaf00d2b26a5de68d",
              "IPY_MODEL_79429dbf59b14657969fc86589efdd80"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "e174503416d54a28ac4f8a93daaf191b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "03dea510ae514d0eaf00d2b26a5de68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4627628527a4ffe8e0bd143cca8c953",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d54a46df48e84ff384f3bd5ce75c1545"
          },
          "model_module_version": "1.5.0"
        },
        "79429dbf59b14657969fc86589efdd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc9b8b3bd66d4e24b17cba90e5bdcc21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/? [00:01&lt;00:00, 133.12it/s, epoch=1, loss=0.692]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_098809f6e1d14eccbe2e348f00c80faf"
          },
          "model_module_version": "1.5.0"
        },
        "e4627628527a4ffe8e0bd143cca8c953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "d54a46df48e84ff384f3bd5ce75c1545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cc9b8b3bd66d4e24b17cba90e5bdcc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "098809f6e1d14eccbe2e348f00c80faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DshJV-igAbAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e756c5-9d98-4234-d9bd-4f514398ab40"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "import nltk\n",
        "from typing import *\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tqdm.notebook import tqdm\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
        "device\n",
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9W9FrzpPkxu",
        "outputId": "b0366d00-078f-40df-a007-89b83e31e682"
      },
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnMl_ZMkzT1"
      },
      "source": [
        "import json\n",
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/nlp2021-hw1/data/train.jsonl\"\n",
        "dev_dataset_path = \"/content/drive/MyDrive/Colab Notebooks/nlp2021-hw1/data/dev.jsonl\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6VYKVvxMdSF"
      },
      "source": [
        "path_to_vocab = 'drive/My Drive/Colab Notebooks/nlp2021-hw1/model/word_vocab.pickle'\n",
        "with open(path_to_vocab, 'rb') as handle:\n",
        "  word_vects = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urAXMV-4Ao24"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "class Vocabulary(object):\n",
        "\n",
        "  def __init__(self, word_vects, add_unk=True, unk_token=\"<UNK>\", sep_token = '<SEP>', add_sep=True, pad_token = '<PAD>', add_pad=True):\n",
        "    \"\"\"\n",
        "    args: \n",
        "    token_to_idx (dict): A pre-existing map of tokens to indices\n",
        "    add_unk (bool): flag indicating to add UNK, to be added to vocabulary\n",
        "    \"\"\"\n",
        "    self.token_to_idx = {k: v for v, k  in enumerate([i for i in word_vects])}\n",
        "    self.idx_to_token = {k: v for k, v  in enumerate([i for i in word_vects])}\n",
        "    self.word_vects = word_vects\n",
        "    self.add_unk = add_unk\n",
        "    self.add_sep = add_sep\n",
        "    self.unk_token = unk_token\n",
        "    self.sep_token = sep_token\n",
        "    self.add_pad = add_pad\n",
        "    self.pad_token = pad_token\n",
        "    if add_unk:\n",
        "      self.unk_index = self.add_token(unk_token)\n",
        "    if add_sep:\n",
        "      self.sep_index = self.add_token(sep_token)\n",
        "    if add_pad:\n",
        "      self.pad_index = self.add_token(pad_token)\n",
        "\n",
        "  def add_token(self, token):\n",
        "    \"update mapping dicts with the input token\"\n",
        "    if token in self.token_to_idx:\n",
        "      index=self.token_to_idx[token]\n",
        "    else:\n",
        "      index = len(self.token_to_idx)\n",
        "      self.token_to_idx[token] = index\n",
        "      self.idx_to_token[index] = token\n",
        "    return index\n",
        "\n",
        "  def find_index(self, token):\n",
        "    \"find the index associated to the input token\"\n",
        "    if self.add_unk:\n",
        "      return self.token_to_idx.get(token, self.unk_index)\n",
        "    else:\n",
        "      return self.token_to_idx[token]\n",
        "  \n",
        "  def find_token(self, index):\n",
        "    \"find the token associated to the input index\"\n",
        "    if index not in self.idx_to_token:\n",
        "      raise KeyError(\"the index (%d) is not in the Vocabulary\")\n",
        "    return self.idx_to_token[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.token_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQtYsh_AE_uq"
      },
      "source": [
        "vocab = Vocabulary(word_vects)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Q7Zi7pFLia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef536606-c849-4e4c-f539-bcff62ed9a01"
      },
      "source": [
        "vocab.__len__()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY-bNW-jg7LZ"
      },
      "source": [
        "class Preprocesser():\n",
        "\n",
        "  def __init__(self, vocab):\n",
        "    self.vocab = vocab\n",
        "    self.cos = nn.CosineSimilarity(dim=1, eps=1e-6).to(device)\n",
        "    self.matrix = self.prepare_matrix(vocab)\n",
        "    self.matrix.to(device)\n",
        "    \n",
        "  def remove_stopwords(self, sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text_tokens = word_tokenize(sentence)\n",
        "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "    tokens_without_sw = [lemmatizer.lemmatize(word).lower() for word in text_tokens if not word in stop]\n",
        "    return tokens_without_sw\n",
        "\n",
        "  def word_to_vec(self, word):\n",
        "    try:\n",
        "      idx = vocab.find_index(word)\n",
        "      return self.matrix[idx]\n",
        "    except KeyError:\n",
        "      return torch.zeros(300).to(device)\n",
        "\n",
        "  def preprocess(self, data):\n",
        "    for entry in data:\n",
        "      start = int(entry[\"start1\"])\n",
        "      end = int(entry[\"end1\"])\n",
        "      entry[\"target\"] = entry[\"sentence1\"][start:end]\n",
        "      entry[\"words_1\"] = self.remove_stopwords(entry[\"sentence1\"])\n",
        "      entry[\"words_2\"] = self.remove_stopwords(entry[\"sentence2\"])\n",
        "      entry[\"idx_1\"] = [self.vocab.find_index(word) for word in entry[\"words_1\"]]\n",
        "      entry[\"idx_2\"] = [self.vocab.find_index(word) for word in entry[\"words_2\"]]\n",
        "      entry[\"X\"] = entry[\"idx_1\"]\n",
        "      entry[\"X\"].append(vocab.sep_index)\n",
        "      entry[\"X\"].extend(entry[\"idx_2\"])\n",
        "      entry[\"X\"].append(vocab.sep_index)\n",
        "      #similars = self.find_similars(self.word_to_vec(entry[\"target\"]))\n",
        "      #print(similars)\n",
        "      #entry[\"X\"].extend(similars)\n",
        "    return data\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  def find_similars(self, word):\n",
        "    word = word.expand(len(self.matrix), -1)\n",
        "    word.to(device)\n",
        "    sims = self.cos(word, self.matrix).cuda()\n",
        "    most_similars = torch.topk(sims, 5).indices.tolist()\n",
        "    return most_similars\n",
        "  \n",
        "\n",
        "  def prepare_matrix(self, vocab):\n",
        "    num_tokens = vocab.__len__()\n",
        "    embedding_dim = len(vocab.word_vects[\"mouse\"])\n",
        "\n",
        "  # Prepare embedding matrix\n",
        "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "    for idx in vocab.idx_to_token:\n",
        "      word = str(vocab.idx_to_token[idx])\n",
        "      if word not in [\"<UNK>\", \"<SEP>\", \"<PAD>\"]:\n",
        "        try:\n",
        "          embedding_matrix[idx] = vocab.word_vects[word]\n",
        "        except:\n",
        "          print(word)\n",
        "\n",
        "      else: \n",
        "        print(word)\n",
        "    return torch.tensor(embedding_matrix)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOnEvCerHRJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a2dca3-b0e5-4b3f-9d54-29fd98e64335"
      },
      "source": [
        "preprocesser = Preprocesser(vocab)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<UNK>\n",
            "<SEP>\n",
            "<PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf5t19RHAzxl"
      },
      "source": [
        "class SentenceDataset(Dataset):\n",
        "   def __init(self, dataset_path):\n",
        "     self.path = dataset_path\n",
        "\n",
        "   def _init_data(self, preprocesser):\n",
        "    self.samples = []\n",
        "    with open(self.path) as f:\n",
        "     lista = list(f)\n",
        "    self.data = []\n",
        "    for json_str in lista:\n",
        "      result = json.loads(json_str)\n",
        "      self.data.append(result)\n",
        "    self.data = preprocesser.preprocess(self.data)\n",
        "    self.get_samples()\n",
        "\n",
        "  \n",
        "   def convert(self, sample):\n",
        "    if sample[\"label\"] == \"True\":\n",
        "      return int(1)\n",
        "    else:\n",
        "      return (0)\n",
        "\n",
        "   def __len__(self):\n",
        "    return len(self.samples)\n",
        "\n",
        "\n",
        "   def __getitem__(self, idx):\n",
        "    return self.samples[idx]\n",
        "\n",
        "   def get_samples(self):\n",
        "    self.samples = [(torch.tensor(entry[\"X\"]), self.convert(entry)) for entry in self.data]\n",
        "\n",
        "   def collate_fn(self, samples):\n",
        "     X = [sample[0] for sample in samples]\n",
        "     lengths = torch.tensor([x.size(0) for x in X], dtype=torch.long).to(device)\n",
        "     X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True, padding_value=400002).to(device)\n",
        "     y = [sample[1] for sample in samples]\n",
        "     y = torch.tensor(y).to(device)\n",
        "\n",
        "     return X, lengths, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q4X4EK5AG9f"
      },
      "source": [
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/nlp2021-hw1/data/train.jsonl\"\n",
        "dev_dataset_path = \"/content/drive/MyDrive/Colab Notebooks/nlp2021-hw1/data/dev.jsonl\"\n",
        "dataset = SentenceDataset()\n",
        "dataset.path = dataset_path\n",
        "dataset._init_data(preprocesser)\n",
        "dev_dataset = SentenceDataset()\n",
        "dev_dataset.path = dev_dataset_path\n",
        "dev_dataset._init_data(preprocesser)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa2PZW0ggtwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5210c0c-3814-43b9-cc2f-a6c4293d8cdc"
      },
      "source": [
        "dataset.data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X': [6,\n",
              "  4710,\n",
              "  6409,\n",
              "  4984,\n",
              "  6689,\n",
              "  802,\n",
              "  638,\n",
              "  282,\n",
              "  546,\n",
              "  2951,\n",
              "  380,\n",
              "  400001,\n",
              "  7,\n",
              "  2148,\n",
              "  282,\n",
              "  1698,\n",
              "  52,\n",
              "  4424,\n",
              "  12818,\n",
              "  87,\n",
              "  122,\n",
              "  400001],\n",
              " 'end1': '73',\n",
              " 'end2': '14',\n",
              " 'id': 'train.0',\n",
              " 'idx_1': [6,\n",
              "  4710,\n",
              "  6409,\n",
              "  4984,\n",
              "  6689,\n",
              "  802,\n",
              "  638,\n",
              "  282,\n",
              "  546,\n",
              "  2951,\n",
              "  380,\n",
              "  400001,\n",
              "  7,\n",
              "  2148,\n",
              "  282,\n",
              "  1698,\n",
              "  52,\n",
              "  4424,\n",
              "  12818,\n",
              "  87,\n",
              "  122,\n",
              "  400001],\n",
              " 'idx_2': [7, 2148, 282, 1698, 52, 4424, 12818, 87, 122],\n",
              " 'label': 'False',\n",
              " 'lemma': 'play',\n",
              " 'pos': 'NOUN',\n",
              " 'sentence1': 'In that context of coordination and integration, Bolivia holds a key play in any process of infrastructure development.',\n",
              " 'sentence2': 'A musical play on the same subject was also staged in Kathmandu for three days.',\n",
              " 'start1': '69',\n",
              " 'start2': '10',\n",
              " 'target': 'play',\n",
              " 'words_1': ['in',\n",
              "  'context',\n",
              "  'coordination',\n",
              "  'integration',\n",
              "  'bolivia',\n",
              "  'hold',\n",
              "  'key',\n",
              "  'play',\n",
              "  'process',\n",
              "  'infrastructure',\n",
              "  'development'],\n",
              " 'words_2': ['a',\n",
              "  'musical',\n",
              "  'play',\n",
              "  'subject',\n",
              "  'also',\n",
              "  'staged',\n",
              "  'kathmandu',\n",
              "  'three',\n",
              "  'day']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHsRWPdENYqr"
      },
      "source": [
        "batch_size = 32\n",
        "train_dataloader = DataLoader(dataset, batch_size= batch_size, collate_fn=dataset.collate_fn)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size= batch_size, collate_fn=dev_dataset.collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEKABErlNYup"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3QXBuRgNYyU"
      },
      "source": [
        "class Lstm_Classifier(nn.Module):\n",
        "  \n",
        "  def __init__(self, matrix, hidden, device):\n",
        "    super().__init__()\n",
        "    self.embedding = torch.nn.Embedding.from_pretrained(matrix).float().to(device)\n",
        "    self.rnn = torch.nn.LSTM(input_size=matrix.size(1), hidden_size=hidden, dropout = 0.15, num_layers=2, bidirectional=False)\n",
        "    self.lin1 = torch.nn.Linear(hidden, hidden)\n",
        "    self.lin2 = torch.nn.Linear(hidden, 1)\n",
        "    self.loss = torch.nn.BCELoss()\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0005)\n",
        "    self.device= device\n",
        "\n",
        "    \n",
        "\n",
        "  def forward(self, X, xlength, y):\n",
        "    embedding_out = self.embedding(X).cuda()\n",
        "    recurrent_out = self.rnn(embedding_out)[0]\n",
        "    batch_size, seq_len, hidden_size = recurrent_out.shape\n",
        "    flattened_out = recurrent_out.reshape(-1, hidden_size)\n",
        "    last_word_relative_indices = xlength - 1\n",
        "    sequences_offsets = torch.arange(batch_size, device=self.device) * seq_len\n",
        "    summary_vectors_indices = sequences_offsets.to(device) + last_word_relative_indices.to(device)\n",
        "    summary_vectors = flattened_out[summary_vectors_indices]\n",
        "    out=self.lin1(summary_vectors)\n",
        "    out = torch.relu(out)\n",
        "    out = self.lin2(out).squeeze(1)\n",
        "    logits = out\n",
        "    m = nn.Sigmoid()\n",
        "    pred = m(logits)\n",
        "    result= {'logits' : logits, 'pred': pred}\n",
        "\n",
        "\n",
        "    if y is not None:\n",
        "      loss = self.loss(pred, y)\n",
        "      result['loss'] = loss\n",
        "      return result\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZR2oxX2HMGz"
      },
      "source": [
        "def training_loop(model: nn.Module, optimizer: torch.optim.Optimizer,  adapt: Callable[[torch.Tensor, torch.Tensor], Tuple[torch.Tensor, torch.Tensor]], epochs: int = 2):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        progress_bar = tqdm()\n",
        "        # batches of the training set\n",
        "        for x, xlength, y in train_dataloader:\n",
        "            x.to(device)\n",
        "            y.to(device)\n",
        "            xlength.to(device)\n",
        "            x, y = adapt(x, y)\n",
        "            optimizer.zero_grad()\n",
        "            batch_out = model(x, xlength, y)\n",
        "            loss = batch_out['loss']\n",
        "\n",
        "            # computes the gradient of the loss\n",
        "            loss.backward()\n",
        "            # updates parameters based on the gradient information\n",
        "            optimizer.step()\n",
        "\n",
        "            progress_bar.update()\n",
        "            progress_bar.set_postfix(epoch=epoch, loss=loss.item())\n",
        "        progress_bar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UagBubEI2m6"
      },
      "source": [
        "embeddings = preprocesser.matrix\n",
        "hidden = 30\n",
        "\n",
        "model = Lstm_Classifier(embeddings, hidden, device).to(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9RnVuYeOY2I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "d6d2f954caaf48d8a442c93d42598e3a",
            "fff377ea8e43457783cb8c0cd063cbe9",
            "90f2647711c54948a8397d7ba8937594",
            "51e3a68893274dddaa9b7ea643aa0850",
            "ba3b6da00fb64217a4f54bd752ac1e1f",
            "f3b28ef7adc54b41b8c52e259a5f0ba1",
            "94024185524844579e319e46f3683b4c",
            "63d63e19d5414d9f8b99818c3fc27543",
            "0d9d3c9c25104702a65403012c61619c",
            "e174503416d54a28ac4f8a93daaf191b",
            "03dea510ae514d0eaf00d2b26a5de68d",
            "79429dbf59b14657969fc86589efdd80",
            "e4627628527a4ffe8e0bd143cca8c953",
            "d54a46df48e84ff384f3bd5ce75c1545",
            "cc9b8b3bd66d4e24b17cba90e5bdcc21",
            "098809f6e1d14eccbe2e348f00c80faf"
          ]
        },
        "outputId": "59235f78-2360-421d-a114-2f032da8ddcd"
      },
      "source": [
        "training_loop(model, model.optimizer, adapt=lambda x, y : (x, y.float()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6d2f954caaf48d8a442c93d42598e3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d9d3c9c25104702a65403012c61619c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_TmUP8LI2pP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4dc1192-e667-4228-ca29-36e8743bdbe2"
      },
      "source": [
        "n = 0\n",
        "d = 0\n",
        "adapt=lambda x, y : (x, y.float())\n",
        "# for each batch in the test set\n",
        "for x, xlength, y in dev_dataloader:\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # classify the batch\n",
        "            x.to(device)\n",
        "            y.to(device)\n",
        "            xlength.to(device)\n",
        "            x, y = adapt(x, y)\n",
        "            batch_out = model(x, xlength, y)\n",
        "            pred = batch_out['pred']\n",
        "            \n",
        "        pred = torch.round(pred)\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "        # number of predictions (corresponding to number of batch items to predict)\n",
        "        d += pred.shape[0]\n",
        "        # number of correct classifications within the batch\n",
        "        n += (y == pred).int().sum()\n",
        "\n",
        "\n",
        "print(f'# accuracy: {(n / d).item():.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# accuracy: 0.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7QDDbs3I2rf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}